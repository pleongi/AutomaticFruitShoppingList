{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.879 - TFM - Área 2 aula 1 - Machine Learning</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Máster universitario de Ciencia de datos (<i>Data Science</i>)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "# Adquisición de datos\n",
    "En este módulo se pretenden descargar las imágenes de ImageNet de las clases manzana, pera, plátano, limón, naranja y piña, para poder obtener un primer conjunto de imágenes de entrenamiento y de validación.\n",
    "Por cada clase descargaremos 100 de entrenamiento y 50 de validación. Asegurando que no existe ninguna imagen que este repetida en la carpeta de entrenamiento y en la de validación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import requests\n",
    "import cv2\n",
    "import urllib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 32, 32 #number of rows and columns to convert the images to\n",
    "input_shape = (img_rows, img_cols, 3)#format to store the images (rows, columns,channels) called channels last\n",
    "def url_to_image(url):\n",
    "    # download the image, convert it to a NumPy array, and then read it into OpenCV format\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "n_of_training_images=200#the number of training images to use\n",
    "n_of_validating_images=50#the number of validating images to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "synsetsIds=['n07739125','n07767847','n07753592','n07749582','n07747607','n07753275']\n",
    "synsetsNames=['apple','pear','banana','lemon','orange','pineapple']\n",
    "\n",
    "for i in range(0,len(synsetsIds)):\n",
    "    url=\"http://www.image-net.org/api/text/imagenet.synset.geturls.getmapping?wnid=\"+synsetsIds[i]\n",
    "    page = requests.get(url)\n",
    "    train_path=\"TensorFlow/workspace/images/train/\"+synsetsNames[i]+\"/\"\n",
    "    validation_path=\"TensorFlow/workspace/images/test/\"+synsetsNames[i]+\"/\"\n",
    "    try:\n",
    "        os.makedirs(train_path)\n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , train_path ,  \" already exists\")\n",
    "    try:\n",
    "        os.makedirs(validation_path)\n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , validation_path ,  \" already exists\")\n",
    "        \n",
    "    #puts the content of the website into the soup variable, each url on a different line\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    str_soup=str(soup)#convert soup to string so it can be split\n",
    "    type(str_soup)\n",
    "    split_urls=str_soup.split('\\r\\n')#split so each url is a different possition on a list\n",
    "    #Train data:\n",
    "    for progress in range(n_of_training_images):#store all the images on a directory\n",
    "        if not split_urls[progress] == None:\n",
    "            try:\n",
    "                I = url_to_image(split_urls[progress].split(' ', 1)[1])\n",
    "                if (len(I.shape))==3: #check if the image has width, length and channels\n",
    "                    save_path = train_path+str(split_urls[progress].split(' ', 1)[0])+'.jpg'#create a name of each image\n",
    "                    cv2.imwrite(save_path,I)\n",
    "            except:\n",
    "                None\n",
    "    #Validation data:\n",
    "    for progress in range(n_of_validating_images):#store all the images on a directory\n",
    "        if not split_urls[progress] == None:\n",
    "            try:\n",
    "                #get images that are different from the ones used for training\n",
    "                I = url_to_image(split_urls[n_of_training_images+progress].split(' ', 1)[1])\n",
    "                if (len(I.shape))==3: #check if the image has width, length and channels\n",
    "                    save_path = validation_path+str(split_urls[n_of_training_images+progress].split(' ', 1)[0])+'.jpg'#create a name of each image\n",
    "                    cv2.imwrite(save_path,I)\n",
    "            except:\n",
    "                None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}